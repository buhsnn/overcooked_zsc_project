{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa4a519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available layouts: ['asymmetric_advantages', 'asymmetric_advantages_tomato', 'bonus_order_test', 'bottleneck', 'centre_objects', 'centre_pots', 'coordination_ring', 'corridor', 'counter_circuit', 'counter_circuit_o_1order', 'cramped_corridor', 'cramped_room', 'cramped_room_o_3orders', 'cramped_room_single', 'cramped_room_tomato', 'five_by_five', 'forced_coordination', 'forced_coordination_tomato', 'inverse_marshmallow_experiment', 'large_room', 'long_cook_time', 'm_shaped_s', 'marshmallow_experiment', 'marshmallow_experiment_coordination', 'mdp_test', 'multiplayer_schelling', 'old_dynamics_cook_test', 'old_dynamics_put_test', 'pipeline', 'random0', 'random3', 'scenario1_s', 'scenario2', 'scenario2_s', 'scenario3', 'scenario4', 'schelling', 'schelling_s', 'simple_o', 'simple_o_t', 'simple_tomato', 'small_corridor', 'soup_coordination', 'tutorial_0', 'tutorial_1', 'tutorial_2', 'tutorial_3', 'unident', 'you_shall_not_pass']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available layouts:\", layouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f69ce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bushra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from env.overcooked_wrapper import OvercookedGym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5a8f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MediumLevelActionManager\n",
      "Observation shape: (96,)\n",
      "Action space: Discrete(6)\n"
     ]
    }
   ],
   "source": [
    "env = OvercookedGym(\"cramped_room\")\n",
    "print(\"Observation shape:\", env.observation_space.shape)\n",
    "print(\"Action space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cc271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=3e-4,\n",
    "    batch_size=64,\n",
    "    n_steps=2048,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d0fc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 682      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 575        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00916202 |\n",
      "|    clip_fraction        | 0.0658     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.78      |\n",
      "|    explained_variance   | -0.298     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0198    |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    value_loss           | 0.0177     |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010505494 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0003     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.00725     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012114942 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0136     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.00411     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 530       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0126874 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.75     |\n",
      "|    explained_variance   | 0.716     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0245   |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0209   |\n",
      "|    value_loss           | 0.0024    |\n",
      "---------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010033928 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0409     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.00188     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 517         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011649234 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0493     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 0.000973    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 517         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009438368 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0252     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.000757    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011765181 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0269     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000472    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012596594 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00236    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.000407    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011088476 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.000296    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 511          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122171715 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0104       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0186      |\n",
      "|    value_loss           | 0.000141     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008403478 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00699    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.000138    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011047313 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0072     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.000118    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 507        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01568511 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | -0.0546    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.000627   |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    value_loss           | 0.000123   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 64         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00851096 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.45      |\n",
      "|    explained_variance   | 0.66       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.003      |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    value_loss           | 8.6e-05    |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009573744 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -0.107      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0236     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 4.32e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009061683 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.0294      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0353     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 2.56e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013017764 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -0.187      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0276     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 3.72e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011971331 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.791      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 2.4e-05     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015702356 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00375     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 2.36e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010880785 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0636     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 5.9e-06     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012097207 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -0.43       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00638    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    value_loss           | 1.25e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011203025 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.0909      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0123     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 1.03e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 101        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01720736 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.49      |\n",
      "|    explained_variance   | -0.181     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0293    |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    value_loss           | 2.15e-06   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00842941 |\n",
      "|    clip_fraction        | 0.0758     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.49      |\n",
      "|    explained_variance   | -0.413     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0216    |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.00763   |\n",
      "|    value_loss           | 2.33e-05   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012607606 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.041       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00639     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 2.13e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012608099 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.184      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00627    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 6.1e-06     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011292596 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -1.52       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000804    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 1.09e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017573705 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 5.9e-06     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016785778 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0278     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    value_loss           | 1.13e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017496724 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | -1.52       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00749     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 6.48e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 400       |\n",
      "|    ep_rew_mean          | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 511       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 132       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0161636 |\n",
      "|    clip_fraction        | 0.233     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.44     |\n",
      "|    explained_variance   | -0.397    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0118   |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -0.0214   |\n",
      "|    value_loss           | 4.39e-06  |\n",
      "---------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010487961 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -1.28       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0553     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 1.17e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011632878 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -2.27       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0342     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 1.77e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 508        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01633615 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | -0.321     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0363    |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    value_loss           | 1.2e-05    |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 509        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 148        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01328529 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | -0.477     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0232    |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    value_loss           | 1.95e-05   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019652061 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0154      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 7.3e-06     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086981375 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -1.04        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0119      |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    value_loss           | 1.63e-05     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009094927 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0169     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 5.91e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012358129 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -0.279      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0313     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 1.54e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012535701 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -1.31       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0322     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 5.73e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018916588 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | -1.44       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0444     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 5.09e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 501        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01652007 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | 0.583      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.04      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    value_loss           | 7.16e-07   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008542629 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | -0.19       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 1.25e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008758137 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000883   |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    value_loss           | 1.52e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022111109 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -1.64       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00581    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 3.43e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013242744 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.44       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0432     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 5.89e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015586428 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.307      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0155     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 2.74e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 204        |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01796676 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.38      |\n",
      "|    explained_variance   | -0.756     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0232    |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    value_loss           | 1.62e-07   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010249731 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -4.25       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00474    |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 4.62e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012799725 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.84       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0402     |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 4.25e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 216        |\n",
      "|    total_timesteps      | 108544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00559232 |\n",
      "|    clip_fraction        | 0.0575     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | -3.47      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00579   |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0084    |\n",
      "|    value_loss           | 1.76e-06   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011933964 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.0978      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 3.15e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 225        |\n",
      "|    total_timesteps      | 112640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01924413 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | -0.518     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0256    |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    value_loss           | 6.75e-07   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011002965 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -3.25       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0239     |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 2.14e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015389047 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.335      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0212     |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    value_loss           | 7.42e-08    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021086914 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -2.55       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0352     |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 1.05e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020577094 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -0.756      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0303     |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 2.67e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 499        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 245        |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03726375 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | -0.741     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00461   |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    value_loss           | 2.24e-05   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013140406 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | -0.567      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0131     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 1.71e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013724649 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.234      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00611     |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 4.47e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009105699 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | -1.29       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 4.12e-08    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 496          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 263          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065403865 |\n",
      "|    clip_fraction        | 0.072        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0134      |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    value_loss           | 7.97e-09     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009577839 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | -5.6        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0237     |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 6.23e-08    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 496          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 272          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093584545 |\n",
      "|    clip_fraction        | 0.0798       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | -3.69        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0317      |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0079      |\n",
      "|    value_loss           | 1.94e-05     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021222185 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -0.381      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0457     |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 4.42e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029595114 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -0.254      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0489     |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 5.54e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 497        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 284        |\n",
      "|    total_timesteps      | 141312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00912975 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | -0.248     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0314     |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.00292   |\n",
      "|    value_loss           | 1.48e-05   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008282818 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.961      |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000721   |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    value_loss           | 3.46e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007351221 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.867      |\n",
      "|    explained_variance   | -0.609      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    value_loss           | 1.2e-06     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 499          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 295          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067209033 |\n",
      "|    clip_fraction        | 0.0885       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.815       |\n",
      "|    explained_variance   | -0.256       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.031       |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0088      |\n",
      "|    value_loss           | 2.38e-05     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029199548 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | -0.418      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00543    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    value_loss           | 7.52e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006979159 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | -0.127      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0141     |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    value_loss           | 1.08e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 500          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 306          |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026353814 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.326       |\n",
      "|    explained_variance   | -0.13        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00102      |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    value_loss           | 1.93e-06     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005534092 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.473      |\n",
      "|    explained_variance   | -0.405      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0272     |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    value_loss           | 7.31e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009958488 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | -0.187      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00213    |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    value_loss           | 2.45e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004331174 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.464      |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000497   |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 6.46e-05    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009653326 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -1.19       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00894    |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 5.22e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 325          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043851994 |\n",
      "|    clip_fraction        | 0.0483       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0311      |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00718     |\n",
      "|    value_loss           | 2.5e-05      |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 329        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01310689 |\n",
      "|    clip_fraction        | 0.0922     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.745     |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0442    |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    value_loss           | 3.63e-06   |\n",
      "----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007825382 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.779      |\n",
      "|    explained_variance   | -0.815      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00613     |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    value_loss           | 5.69e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 337          |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050436445 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0131      |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00893     |\n",
      "|    value_loss           | 1.54e-05     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 340          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064460016 |\n",
      "|    clip_fraction        | 0.0831       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.764       |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0404      |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.00981     |\n",
      "|    value_loss           | 5.99e-06     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008421984 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.374      |\n",
      "|    explained_variance   | -0.019      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0273     |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    value_loss           | 4.99e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 348          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015166951 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.242       |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0261      |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    value_loss           | 1.37e-06     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010738241 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.045      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    value_loss           | 1.9e-05     |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 355          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020648404 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.279       |\n",
      "|    explained_variance   | -0.315       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0196      |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    value_loss           | 1.32e-05     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 359          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019810386 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.152       |\n",
      "|    explained_variance   | -0.0502      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00272     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 7.27e-07     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012720205 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.168      |\n",
      "|    explained_variance   | -0.259      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    value_loss           | 8.69e-07    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 367          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017439707 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | -0.0179      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00154     |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 4.92e-07     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009248659 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.211      |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 2.73e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004066323 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.238      |\n",
      "|    explained_variance   | -0.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0162     |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.000217   |\n",
      "|    value_loss           | 1.75e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004514963 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.373      |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00644     |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    value_loss           | 4.29e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006298526 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0322      |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 2.18e-06    |\n",
      "-----------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 509          |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 385          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029440052 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.298       |\n",
      "|    explained_variance   | -4.47        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00733     |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    value_loss           | 4.77e-06     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 509          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 389          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036577897 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.341       |\n",
      "|    explained_variance   | -0.573       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0104      |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 7.97e-06     |\n",
      "------------------------------------------\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 393          |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087211095 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000247     |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.00843     |\n",
      "|    value_loss           | 8.51e-06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x19a0446c850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97d99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ppo_student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7522b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de layouts disponibles : 49\n",
      "---- Layouts ----\n",
      "- asymmetric_advantages\n",
      "- asymmetric_advantages_tomato\n",
      "- bonus_order_test\n",
      "- bottleneck\n",
      "- centre_objects\n",
      "- centre_pots\n",
      "- coordination_ring\n",
      "- corridor\n",
      "- counter_circuit\n",
      "- counter_circuit_o_1order\n",
      "- cramped_corridor\n",
      "- cramped_room\n",
      "- cramped_room_o_3orders\n",
      "- cramped_room_single\n",
      "- cramped_room_tomato\n",
      "- five_by_five\n",
      "- forced_coordination\n",
      "- forced_coordination_tomato\n",
      "- inverse_marshmallow_experiment\n",
      "- large_room\n",
      "- long_cook_time\n",
      "- m_shaped_s\n",
      "- marshmallow_experiment\n",
      "- marshmallow_experiment_coordination\n",
      "- mdp_test\n",
      "- multiplayer_schelling\n",
      "- old_dynamics_cook_test\n",
      "- old_dynamics_put_test\n",
      "- pipeline\n",
      "- random0\n",
      "- random3\n",
      "- scenario1_s\n",
      "- scenario2\n",
      "- scenario2_s\n",
      "- scenario3\n",
      "- scenario4\n",
      "- schelling\n",
      "- schelling_s\n",
      "- simple_o\n",
      "- simple_o_t\n",
      "- simple_tomato\n",
      "- small_corridor\n",
      "- soup_coordination\n",
      "- tutorial_0\n",
      "- tutorial_1\n",
      "- tutorial_2\n",
      "- tutorial_3\n",
      "- unident\n",
      "- you_shall_not_pass\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "layout_dir = r\"C:\\Users\\Bushra\\BDML1\\S9\\overcooked_ai\\src\\overcooked_ai_py\\data\\layouts\"\n",
    "\n",
    "layouts = sorted([\n",
    "    f.replace(\".layout\", \"\")\n",
    "    for f in os.listdir(layout_dir)\n",
    "    if f.endswith(\".layout\")\n",
    "])\n",
    "\n",
    "print(\"Nombre de layouts disponibles :\", len(layouts))\n",
    "print(\"---- Layouts ----\")\n",
    "for name in layouts:\n",
    "    print(\"-\", name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ee0467a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout: cramped_room\n",
      "\n",
      "XXPXX\n",
      "O   O\n",
      "X   X\n",
      "XDXSX\n"
     ]
    }
   ],
   "source": [
    "from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld\n",
    "\n",
    "def print_layout(layout_name=\"cramped_room\"):\n",
    "    mdp = OvercookedGridworld.from_layout_name(layout_name)\n",
    "    grid = mdp.terrain_mtx\n",
    "    \n",
    "    print(f\"Layout: {layout_name}\\n\")\n",
    "    for row in grid:\n",
    "        print(\"\".join(row))\n",
    "\n",
    "print_layout(\"cramped_room\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf79f5e",
   "metadata": {},
   "source": [
    "- X : Wall (blocked)\n",
    "- P : Player Spawn\n",
    "- O : Onion\n",
    "- D : Dish\n",
    "- S : pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c004b99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MediumLevelActionManager\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Computing MediumLevelActionManager\n",
      "1 0\n",
      "1 0\n",
      "4 0\n",
      "1 0\n",
      "1 0\n",
      "4 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from env.overcooked_wrapper import OvercookedGym\n",
    "\n",
    "env = OvercookedGym(\"cramped_room\")\n",
    "model = PPO.load(\"ppo_student\", env=env)\n",
    "\n",
    "obs, _ = env.reset()\n",
    "for i in range(10):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, trunc, info = env.step(action)\n",
    "    print(action, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da4800de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from env.overcooked_wrapper import OvercookedGym\n",
    "from overcooked_ai_py.agents.agent import Agent\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb133dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from overcooked_ai_py.mdp.actions import Action\n",
    "\n",
    "class PPOStudentAgent:\n",
    "    \"\"\"\n",
    "    Overcooked-compatible agent that wraps a Stable-Baselines3 PPO model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, featurize_fn):\n",
    "        self.model = model\n",
    "        self.featurize_fn = featurize_fn\n",
    "        self.agent_index = None\n",
    "        self.mdp = None\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Required by Overcooked Agent API.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_agent_index(self, idx):\n",
    "        \"\"\"Overcooked gives agent 0 or 1.\"\"\"\n",
    "        self.agent_index = idx\n",
    "\n",
    "    def set_mdp(self, mdp):\n",
    "        \"\"\"Required by AgentEvaluator  store reference to MDP.\"\"\"\n",
    "        self.mdp = mdp\n",
    "\n",
    "    def action(self, state):\n",
    "        \"\"\"\n",
    "        Called at every step by Overcooked.\n",
    "        Must return:\n",
    "            (overcooked_action, info_dict)\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. Featurize state\n",
    "        obs0, obs1 = self.featurize_fn(state)\n",
    "        obs = obs0 if self.agent_index == 0 else obs1\n",
    "\n",
    "        # 2. PPO predicts discrete action index\n",
    "        action_idx, _ = self.model.predict(obs, deterministic=True)\n",
    "\n",
    "        # 3. Convert to Overcooked action\n",
    "        oc_action = Action.INDEX_TO_ACTION[action_idx]\n",
    "\n",
    "        return oc_action, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6f9dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MediumLevelActionManager\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = OvercookedGym(\"cramped_room\")\n",
    "model = PPO.load(\"ppo_student\", env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa67af6",
   "metadata": {},
   "source": [
    "## intialize agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f1401eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurize_fn = env.env.featurize_state_mdp\n",
    "\n",
    "agent0 = PPOStudentAgent(model, featurize_fn)\n",
    "agent1 = PPOStudentAgent(model, featurize_fn)\n",
    "\n",
    "pair = AgentPair(agent0, agent1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1c79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 400.00; : 100%|| 1/1 [00:00<00:00,  2.63it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594b596abe6545859f2107ac82bb71f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trajs = ae.evaluate_agent_pair(pair, num_games=1)\n",
    "\n",
    "from overcooked_ai_py.visualization.state_visualizer import StateVisualizer\n",
    "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
